{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EllaScheltinga/Deep-Learning-Group-75/blob/main/AEGNN_(ncaltech101).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRbypG14mMIl"
      },
      "source": [
        "### **Setting device and importing dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJKMV41jOmrW",
        "outputId": "a9938131-3e15-4cd8-a784-7dfa1ff846d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEdWIcdcOu-Z"
      },
      "outputs": [],
      "source": [
        "#David\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Onderwijs/TU Delft: MSc RO/AEGNN/src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOx-QLbZFCco"
      },
      "outputs": [],
      "source": [
        "# Ella\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/AEGNN/src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga5AWPlRQjST",
        "outputId": "6bfa68b9-a5dc-40ec-d96b-8a7198db0bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.8.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch_geometric\n",
        "!pip install pytorch-lightning\n",
        "!pip install -q torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylFsvMeKL3p-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#Additional Setup to use Tensorboard\n",
        "!pip install -q tensorflow\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kzh1Uk6mXhN"
      },
      "source": [
        "### **Loading and preprocessing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dMU06RXOtOF",
        "outputId": "c3519ea7-7092-41d0-89a8-a83a653ec302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Onderwijs/TU Delft: MSc RO/AEGNN/data/Caltech101.zip\n"
          ]
        }
      ],
      "source": [
        "!unzip -u \"/content/drive/MyDrive/Onderwijs/TU Delft: MSc RO/AEGNN/data/Caltech101.zip\" -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdFOU_GTRm3y",
        "outputId": "f12b1da8-1d88-45a0-f462-b528cafb9484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace /content/Caltech101/accordion/image_0001.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip -q /content/drive/MyDrive/Caltech101.zip -d /content/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnSkN6JKI2XY"
      },
      "outputs": [],
      "source": [
        "def read_label(raw_file):\n",
        "    return raw_file.split(\"/\")[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxASwoo8JMMD"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "glob_ = glob.glob(os.path.join(\"/content/Caltech101/*\",\"*\"), recursive=True)\n",
        "classes = {}\n",
        "item_id = 0\n",
        "for item in glob_:\n",
        "  class_ = read_label(item)\n",
        "  if class_ not in classes.keys():\n",
        "    classes[class_] = item_id\n",
        "    item_id += 1\n",
        "\n",
        "# classes = {\n",
        "#     'umbrella': 0,\n",
        "#     'butterfly': 1,\n",
        "#     'barrel': 2\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAki1T-bvDal"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8WcdZF_QFp2",
        "outputId": "ae25ff57-7601-458e-8301-f3dcc43677a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "llama\n",
            "kangaroo\n",
            "ketch\n",
            "soccer_ball\n",
            "laptop\n",
            "wrench\n",
            "wheelchair\n",
            "bass\n",
            "starfish\n",
            "menorah\n"
          ]
        }
      ],
      "source": [
        "from utils.load import load_object\n",
        "from utils.preprocess import pre_transform_all\n",
        "\n",
        "data = []\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "#for key in ['umbrella', 'butterfly', 'barrel']:\n",
        "for key in list(classes.keys())[:NUM_CLASSES]:\n",
        "  print(key)\n",
        "  raw = load_object(key)\n",
        "  data += pre_transform_all(raw, classes[key], device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeNDgh22VAnE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split as Split\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "BATCH_SIZE  = 4\n",
        "validation, test, train = Split(data, [0.1, 0.1, 0.8])\n",
        "validation, test, train = DataLoader(validation.dataset, batch_size = BATCH_SIZE),\\\n",
        "                          DataLoader(test.dataset, batch_size = BATCH_SIZE),\\\n",
        "                          DataLoader(train.dataset, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYIJiV5JmklY"
      },
      "source": [
        "### **Training model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx2yVlZYVM5A"
      },
      "outputs": [],
      "source": [
        "import torch.optim\n",
        "from models.recognition import RecognitionModel\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "rm = RecognitionModel(network=\"graph_res\", dataset=\"ncaltech101\", num_classes=NUM_CLASSES, img_shape=(240,180)).to(device)\n",
        "optimizer = torch.optim.Adam(rm.parameters(), lr = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nsCXG2jfQnW"
      },
      "outputs": [],
      "source": [
        "def training(model, data):\n",
        "  seen = 0\n",
        "  correct = 0\n",
        "  # Create a writer to write to Tensorboard\n",
        "  for item in iter(data):\n",
        "      item = item.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      out = model.forward(item)\n",
        "      loss = criterion(out, item.y)\n",
        "      loss.backward()\n",
        "      pred = out.max(dim=1)[1]\n",
        "      seen += len(item)\n",
        "      correct += pred.eq(item.y).sum().item()\n",
        "      optimizer.step()\n",
        "\n",
        "  return correct / seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N17svSK3j0uT"
      },
      "outputs": [],
      "source": [
        "def validating(model, data):\n",
        "    seen = 0\n",
        "    correct = 0\n",
        "    for item in iter(data):\n",
        "        item = item.to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model.forward(item)\n",
        "            pred = out.max(dim=1)[1]\n",
        "            seen += len(item)\n",
        "            correct += pred.eq(item.y).sum().item()\n",
        "\n",
        "    return correct / seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuyWaK5oKOcJ"
      },
      "outputs": [],
      "source": [
        "def testing(model, data):\n",
        "    seen = 0\n",
        "    correct = 0\n",
        "    for item in iter(data):\n",
        "        item = item.to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model.forward(item)\n",
        "            pred = out.max(dim=1)[1]\n",
        "            seen += len(item)\n",
        "            correct += pred.eq(item.y).sum().item()\n",
        "\n",
        "    return correct / seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMQbpAdSjt9p",
        "outputId": "1921d30b-2893-4477-9928-00de7be2ed90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000, train acc.: 0.7433, val. acc.: 0.1096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:09<02:18,  9.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001, train acc.: 0.7313, val. acc.: 0.1096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:17<01:47,  8.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002, train acc.: 0.6912, val. acc.: 0.1096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [00:21<01:20,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003, train acc.: 0.7219, val. acc.: 0.1096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [00:26<01:05,  5.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004, train acc.: 0.6898, val. acc.: 0.1150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [00:31<00:54,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005, train acc.: 0.6564, val. acc.: 0.1364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [00:36<00:48,  5.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006, train acc.: 0.7139, val. acc.: 0.1618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [00:41<00:41,  5.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007, train acc.: 0.7527, val. acc.: 0.1965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [00:45<00:35,  5.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008, train acc.: 0.7901, val. acc.: 0.2500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [00:51<00:30,  5.08s/it]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "highest_acc = 0\n",
        "num_epoch = 15\n",
        "model = rm\n",
        "\n",
        "av_hist = np.zeros((num_epoch, 3))\n",
        "writer = SummaryWriter()\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "  train_acc = training(model = model, data = train)\n",
        "  validation_acc = validating(model = model, data = validation)\n",
        "\n",
        "  av_hist[epoch]=np.array([epoch, train_acc, validation_acc])\n",
        "\n",
        "  # Write metrics to Tensorboard\n",
        "  writer.add_scalar('Train Accuracy', train_acc , epoch)\n",
        "  writer.add_scalar('Validation Accuracy', validation_acc , epoch)\n",
        "\n",
        "\n",
        "  if validation_acc > highest_acc:\n",
        "      torch.save(model.state_dict(), 'best_model.pt')\n",
        "      highest_acc = validation_acc\n",
        "\n",
        "  print(f'Epoch {epoch:03d}, train acc.: {train_acc:.4f}, val. acc.: {validation_acc:.4f}',\n",
        "                              flush = True)\n",
        "print('\\nFinished.')\n",
        "writer.flush()\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Fh1lZ0mqpx"
      },
      "source": [
        "### **Running model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ag0qAwrJnD4i",
        "outputId": "2186f462-6043-4162-93fa-035e7a37784c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Run Tensorboard\n",
        "# !rm -r runs\n",
        "%tensorboard --logdir runs/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PRbypG14mMIl"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}